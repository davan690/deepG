% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train.R
\name{train_lstm}
\alias{train_lstm}
\title{Train  LSTM model}
\usage{
train_lstm(dat, run_name = "run", maxlen = 30, dropout_rate = 0.3,
  layer_size = 128, batch_size = 256, num_layers_lstm = 2,
  codon_cnn = T, validation_split = 0.05, learning_rate = 0.001,
  cudnn = FALSE, multiple_gpu = FALSE, cpu_merge = TRUE,
  gpu_num = 2, vocabulary_size = 5, epochs = 1, verbose = F)
}
\arguments{
\item{dat}{preprocessed input data (semi-redundant chunks)}

\item{run_name}{name of the run (without file ending)}

\item{maxlen}{time steps to unroll for (e.g. length of semi-redundant chunks)}

\item{dropout_rate}{dropout rate for LSTM}

\item{layer_size}{number of cells per network layer}

\item{batch_size}{how many chunks are trained in parallel}

\item{num_layers_lstm}{number of LSTM layers}

\item{codon_cnn}{first layer is a CNN layer with size of 3}

\item{validation_split}{proportion of training set that will be used for validation}

\item{learning_rate}{learning rate for optimizer}

\item{cudnn}{if true, using layer_cudnn_lstm() instead of layer_lstm()}

\item{multiple_gpu}{if true, multi_gpu_model will be used}

\item{cpu_merge}{true on default, false recommend for NVlink, only relevant if multiple_gpu is true}

\item{gpu_num}{number of GPUs to be used, only relevant if multiple_gpu is true}

\item{vocabulary_size}{number of unique chars in training set'}

\item{epochs}{number of full iterations over the dataset#}

\item{verbose}{TRUE/FALSE}

\item{layer_size}{number of cells per network layer#'}
}
\description{
Train  LSTM model
}
